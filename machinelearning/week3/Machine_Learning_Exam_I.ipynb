{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOx+d6wD3UzyglDCPm1bqNF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clementeaf/codingDojo-DS/blob/main/machinelearning/week3/Machine_Learning_Exam_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yHeS9VLVSoQ",
        "outputId": "1df8f3b7-9f7d-4f93-b1ca-80b41a039b5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CQPNmHHbVf8V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.- Cargar los datos"
      ],
      "metadata": {
        "id": "oOKSR08lWg8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/drug200.csv')\n"
      ],
      "metadata": {
        "id": "-J7PxUeWWSI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.- Revisar datos faltantes por columna"
      ],
      "metadata": {
        "id": "oG4shOECXT1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener los nombres de las columnas\n",
        "column_names = df.columns\n",
        "\n",
        "# Obtener la cantidad de datos faltantes en cada columna\n",
        "missing_values = df.isna().sum()\n",
        "\n",
        "# Crear un DataFrame con los resultados\n",
        "results = pd.DataFrame({\"Missing values\": missing_values})\n",
        "\n",
        "# Imprimir el DataFrame\n",
        "print(results)"
      ],
      "metadata": {
        "id": "pBadINP3WyfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.- Verificar si los datos existentes corresponden al tipo de datos por columna que indica el diccionario facilitado en el enunciado"
      ],
      "metadata": {
        "id": "BBf7IGI0X8wx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diccionario:\n",
        "data_types = {\n",
        "    'Drug': object,\n",
        "    'Age': int,\n",
        "    'Sex': object,\n",
        "    'BP': object,\n",
        "    'Cholesterol': object,\n",
        "    'Na_to_K': float\n",
        "}\n",
        "\n",
        "# Lista para almacenar las columnas con datos incorrectos\n",
        "incorrect_data_columns = []\n",
        "\n",
        "# Verificar los tipos de dato en cada columna\n",
        "for column, dtype in data_types.items():\n",
        "    if df[column].dtype != dtype:\n",
        "        incorrect_data_columns.append(column)\n",
        "\n",
        "# Mostrar las columnas con datos incorrectos (si las hay)\n",
        "if len(incorrect_data_columns) > 0:\n",
        "    print(\"Las siguientes columnas tienen datos incorrectos:\")\n",
        "    for column in incorrect_data_columns:\n",
        "        print(f\"- {column}\")\n",
        "else:\n",
        "    print(\"Todos los datos cumplen con los tipos de dato correspondientes.\")"
      ],
      "metadata": {
        "id": "_GdJs1X0YI0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.- Verificación de varlores categóricos"
      ],
      "metadata": {
        "id": "pg9k8NVAY7LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las columnas con tipos de dato categóricos\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Mostrar las variables categóricas\n",
        "print(\"Variables categóricas en el conjunto de datos:\")\n",
        "for column in categorical_columns:\n",
        "    print(f\"- {column}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBcheO4bZBsQ",
        "outputId": "f8ebd727-5b15-40ec-ce5b-1cbdf36b2564"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variables categóricas en el conjunto de datos:\n",
            "- Sex\n",
            "- BP\n",
            "- Cholesterol\n",
            "- Drug\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.- Identificar la cantidad de categórias únicas en cada columna categórica:"
      ],
      "metadata": {
        "id": "vrCjeB1-aY08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in categorical_columns:\n",
        "    unique_categories = df[column].nunique()\n",
        "    print(f\"{column}: {unique_categories} categorías únicas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09DamqFnajN9",
        "outputId": "5c820556-7bea-4c3c-f842-8a05fbeff0e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sex: 2 categorías únicas\n",
            "BP: 3 categorías únicas\n",
            "Cholesterol: 2 categorías únicas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.- Distribución de categŕias"
      ],
      "metadata": {
        "id": "oQ8Wha6IbgCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para mostrar las etiquetas con cantidades y porcentajes\n",
        "def show_labels(ax):\n",
        "    for p in ax.patches:\n",
        "        ax.annotate(f'{p.get_height()}\\n({p.get_height() / len(df) * 100:.1f}%)',\n",
        "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                    ha='center', va='center', fontsize=10, color='black', xytext=(0, 5), textcoords='offset points')\n",
        "\n",
        "# Visualizar la distribución de categorías en \"Sex\"\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.countplot(data=df, x='Sex')\n",
        "plt.title('Distribución de Género')\n",
        "plt.xlabel('Género')\n",
        "plt.ylabel('Frecuencia')\n",
        "show_labels(ax)\n",
        "plt.show()\n",
        "\n",
        "# Visualizar la distribución de categorías en \"BP\"\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.countplot(data=df, x='BP')\n",
        "plt.title('Distribución de Niveles de Presión Arterial')\n",
        "plt.xlabel('Niveles de Presión Arterial')\n",
        "plt.ylabel('Frecuencia')\n",
        "show_labels(ax)\n",
        "plt.show()\n",
        "\n",
        "# Visualizar la distribución de categorías en \"Cholesterol\"\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.countplot(data=df, x='Cholesterol')\n",
        "plt.title('Distribución de Niveles de Colesterol')\n",
        "plt.xlabel('Niveles de Colesterol')\n",
        "plt.ylabel('Frecuencia')\n",
        "show_labels(ax)\n",
        "plt.show()\n",
        "\n",
        "# Visualizar la distribución de categorías en \"Drug\"\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.countplot(data=df, x='Drug')\n",
        "plt.title('Distribución de Tipos de Fármacos (Objetivo)')\n",
        "plt.xlabel('Tipo de Fármaco')\n",
        "plt.ylabel('Frecuencia')\n",
        "show_labels(ax)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Calcular y mostrar la diferencia en las distribuciones\n",
        "differences = {\n",
        "    'Sex': df['Sex'].value_counts().diff().dropna().mean(),\n",
        "    'BP': df['BP'].value_counts().diff().dropna().mean(),\n",
        "    'Cholesterol': df['Cholesterol'].value_counts().diff().dropna().mean(),\n",
        "    'Drug': df['Drug'].value_counts().diff().dropna().mean()\n",
        "}\n",
        "\n",
        "print(\"Diferencia promedio en las distribuciones:\")\n",
        "for column, diff in differences.items():\n",
        "    if column == 'Drug':\n",
        "        if diff > 45:  # Ajusta este umbral según consideres apropiado\n",
        "            diff_label = \"alta\"\n",
        "        elif diff > 15:\n",
        "            diff_label = \"media\"\n",
        "        else:\n",
        "            diff_label = \"baja\"\n",
        "    else:\n",
        "        if diff > 5:\n",
        "            diff_label = \"alta\"\n",
        "        elif diff > 2:\n",
        "            diff_label = \"media\"\n",
        "        else:\n",
        "            diff_label = \"baja\"\n",
        "    print(f\"- {column}: {diff:.2f} ({diff_label} diferencia)\")"
      ],
      "metadata": {
        "id": "ETH55AGcbj07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.- Relación con la Variable Objetivo"
      ],
      "metadata": {
        "id": "AHx7_auddmVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear gráficos de barras para la relación entre cada variable categórica y la variable objetivo\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(data=df, x='Sex', hue='Drug')\n",
        "plt.title('Relación entre Género y Tipo de Fármaco')\n",
        "plt.xlabel('Género')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.countplot(data=df, x='BP', hue='Drug')\n",
        "plt.title('Relación entre Niveles de Presión Arterial y Tipo de Fármaco')\n",
        "plt.xlabel('Niveles de Presión Arterial')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.countplot(data=df, x='Cholesterol', hue='Drug')\n",
        "plt.title('Relación entre Niveles de Colesterol y Tipo de Fármaco')\n",
        "plt.xlabel('Niveles de Colesterol')\n",
        "plt.ylabel('Frecuencia')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xVUPHpGedrzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### .8- Correlación\n",
        "#### Uso de coeficiente de Cramer's V (mide la fuerza y la dirección de la asosiación entre dos variables categóricas)"
      ],
      "metadata": {
        "id": "TosUgwTYgC-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install researchpy"
      ],
      "metadata": {
        "id": "etQmiTodgw8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import researchpy as rp\n",
        "from scipy.stats import chi2_contingency"
      ],
      "metadata": {
        "id": "wq6HW12Cg4Jp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la correlación entre variables categóricas y la variable objetivo\n",
        "correlation_results = []\n",
        "\n",
        "for column in categorical_columns:\n",
        "    table, results = rp.crosstab(df[column], df['Drug'], test='chi-square')\n",
        "    cramers_v = results['results'][2]\n",
        "    correlation_results.append((column, cramers_v))\n",
        "\n",
        "# Mostrar los resultados de correlación\n",
        "for column, correlation in correlation_results:\n",
        "    print(f\"Correlación entre {column} y Drug: {correlation:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nViXufDIgG2N",
        "outputId": "ce700e27-1828-414a-b3fc-e4666127971d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlación entre Sex y Drug: 0.1029\n",
            "Correlación entre BP y Drug: 0.5984\n",
            "Correlación entre Cholesterol y Drug: 0.3131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.- Análisis de Frecuencia"
      ],
      "metadata": {
        "id": "xseO5dxgn8SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=df, x='Drug', order=df['Drug'].value_counts().index)\n",
        "plt.title('Distribución de Tipos de Fármacos')\n",
        "plt.xlabel('Tipo de Fármaco')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rEwjUr0MoNGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.- Análisis preliminar:\n",
        "\n",
        "#### Distribución de categorías: las variables categóricas \"Sex\", \"BP\", \"Cholesterol\" y \"Drug\" tiene un valor razonable de categorías únicas y no parece haber un orden inherente en las categorías\n",
        "\n",
        "#### Relacion con la Variable Objetivo: Se analizó la relación entre las variables categóricas y la variable objetivo, observando su ditribución en virtud a los diferentes fármacos\n",
        "\n",
        "#### Correlación y anaálisis de frecuencia: Uso del coeficiente Cramer's V, aun cuando las correlaciones no son extremadamente altas, persiste evidencia de que las variables categóricas están relacionadas con el tipo de fármaco\n",
        "\n",
        "#### Diferencia en distribuciones: Aún cuando la diferencia en las distribuciones pueden variar, en general, se avista que estas son sustanciales en algunos casos, lo que respalda la idea de que estas variables categóricas podrían ser relevantes para la predicción.\n",
        "\n",
        "#### Conforme a lo anteior, la docidificaciónm \"on-hot\" se aprecia como la opción más sólida para capturar las relaciones y difrencias entre las categorías en las variables categóricas.\n",
        "\n",
        "#### De todos modos, se procederá e evaluar esta premisa conforme a la prueba de modelo para confirmar el tipo de codificación"
      ],
      "metadata": {
        "id": "q3AW1huGpBS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.- Codificación On-Hot"
      ],
      "metadata": {
        "id": "T9AtOzrDrPP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar la codificación one-hot para las variables categóricas\n",
        "df_encoded = pd.get_dummies(df, columns=['Sex', 'BP', 'Cholesterol', 'Drug'], drop_first=True)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame codificado\n",
        "print(df_encoded.head())"
      ],
      "metadata": {
        "id": "yProI4qDrSh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos de Predicción"
      ],
      "metadata": {
        "id": "ZF1EMZEf7zET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12.- Random Forest"
      ],
      "metadata": {
        "id": "ZyASDCYkryo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Definir las características (X) y la variable objetivo (y)\n",
        "X = df_encoded.drop(['Drug_drugA', 'Drug_drugB', 'Drug_drugC', 'Drug_drugX'], axis=1)\n",
        "y = df_encoded[['Drug_drugA', 'Drug_drugB', 'Drug_drugC', 'Drug_drugX']]\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Crear y entrenar un modelo de Random Forest\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predecir con el modelo de Random Forest\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluar el rendimiento del modelo de Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "classification_report_rf = classification_report(y_test, y_pred_rf, zero_division=1)\n",
        "\n",
        "print(f\"Accuracy del modelo de Random Forest: {accuracy_rf:.4f}\")\n",
        "print(\"Reporte de clasificación del modelo de Random Forest:\")\n",
        "print(classification_report_rf)"
      ],
      "metadata": {
        "id": "W3Vy9t21r3ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 12.1 Random Forest Matriz de confusión"
      ],
      "metadata": {
        "id": "TP5XqwRDDZdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test.values.argmax(axis=1), y_pred_rf.argmax(axis=1))\n",
        "\n",
        "# Etiquetas de las clases\n",
        "class_labels = ['Drug_drugA', 'Drug_drugB', 'Drug_drugC', 'Drug_drugX']\n",
        "\n",
        "# Crear una figura y un eje\n",
        "plt.figure(figsize=(8, 6))\n",
        "ax = plt.subplot()\n",
        "\n",
        "# Generar la matriz de confusión con colores\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels, ax=ax)\n",
        "\n",
        "# Configurar etiquetas de los ejes\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('True')\n",
        "ax.set_title('Matriz de Confusión - Random Forest')\n",
        "\n",
        "# Mostrar la leyenda de colores\n",
        "cbar = ax.collections[0].colorbar\n",
        "cbar.set_ticks([0, 1, 2, 3])\n",
        "cbar.set_ticklabels(class_labels)\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "shric92V79PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13.- Regresión Logística Multiclase"
      ],
      "metadata": {
        "id": "ODrYqE_WwBKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Cargar los datos y codificar las variables categóricas\n",
        "label_encoders = {}\n",
        "categorical_columns = ['Sex', 'BP', 'Cholesterol', 'Drug']\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[column] = le.fit_transform(df[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# Definir características (X) y variable objetivo (y)\n",
        "X = df.drop('Drug', axis=1)\n",
        "y = df['Drug']\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Crear el modelo de Regresión Logística Multiclase\n",
        "logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
        "\n",
        "# Entrenar el modelo\n",
        "logistic_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predecir con el modelo\n",
        "y_pred = logistic_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluar el rendimiento del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report_logistic = classification_report(y_test, y_pred, zero_division=1)\n",
        "\n",
        "print(f\"Accuracy del modelo de Regresión Logística: {accuracy:.4f}\")\n",
        "print(\"Reporte de clasificación del modelo de Regresión Logística:\")\n",
        "print(classification_report_logistic)"
      ],
      "metadata": {
        "id": "v1eVuksTv9r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 13.1 .- Matriz de confusión para Regresión Logística Multiclase"
      ],
      "metadata": {
        "id": "-L9jquUL-bNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Obtener las clases únicas\n",
        "unique_classes = sorted(y_test.unique())\n",
        "\n",
        "# Crear una figura y un eje\n",
        "plt.figure(figsize=(10, 8))\n",
        "ax = plt.subplot()\n",
        "\n",
        "# Generar la matriz de confusión con colores\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=unique_classes, yticklabels=unique_classes, ax=ax)\n",
        "\n",
        "# Configurar etiquetas de los ejes\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('True')\n",
        "ax.set_title('Matriz de Confusión - Regresión Logística Multiclase')\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ONDvxjXI-hl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14.- K-Nearest Neighbors (KNN)"
      ],
      "metadata": {
        "id": "Cu7fnWauw00P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Definir características (X) y variable objetivo (y)\n",
        "X = df_encoded.drop(['Drug_drugA', 'Drug_drugB', 'Drug_drugC', 'Drug_drugX'], axis=1)\n",
        "y = df_encoded[['Drug_drugA', 'Drug_drugB', 'Drug_drugC', 'Drug_drugX']]\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Crear y entrenar un modelo de K-Nearest Neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=10, weights='distance', p=2)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predecir con el modelo de K-Nearest Neighbors\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluar el rendimiento del modelo de K-Nearest Neighbors\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "classification_report_knn = classification_report(y_test, y_pred_knn, zero_division=1)\n",
        "\n",
        "# Análisis del rendimiento del modelo KNN\n",
        "print(f\"Accuracy del modelo de K-Nearest Neighbors: {accuracy_knn:.4f}\")\n",
        "print(\"Reporte de clasificación del modelo de K-Nearest Neighbors:\")\n",
        "print(classification_report_knn)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Interpretación de los resultados\n",
        "print(\"Interpretación de los resultados:\")\n",
        "print(f\"Accuracy: El accuracy del modelo KNN en el conjunto de prueba es del {accuracy_knn:.4f}, lo que significa que aproximadamente el {accuracy_knn * 100:.1f}% de las predicciones del modelo coinciden con las etiquetas reales en el conjunto de prueba. Un accuracy alto generalmente es deseado, pero debes considerar el contexto y el equilibrio de clases.\")\n",
        "print(\"\\n\")\n",
        "print(\"Precision, Recall y F1-Score: Estas métricas son útiles para evaluar el rendimiento del modelo en cada clase individualmente. En general, el modelo tiene buenas precisiones para la mayoría de las clases. Sin embargo, para la clase '2' (Drug_drugC), la precisión es 1.00 y el recall es 0.80, lo que podría indicar que el modelo puede estar cometiendo algunos falsos negativos en esa clase. La clase '0' (Drug_drugA) también tiene un recall de 0.83, lo que sugiere cierta dificultad en identificar todas las instancias de esa clase. Es importante considerar que estas métricas pueden variar según las preferencias y prioridades del problema.\")\n"
      ],
      "metadata": {
        "id": "lQLNskkTzxkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 14.1.- Matriz de confusión para: K-Nearest Neighbors (KNN)"
      ],
      "metadata": {
        "id": "H4t35deK_0ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Obtener la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test.values.argmax(axis=1), y_pred_knn.argmax(axis=1))\n",
        "\n",
        "# Etiquetas de las clases\n",
        "class_labels = ['Drug_drugA', 'Drug_drugB', 'Drug_drugC', 'Drug_drugX']\n",
        "\n",
        "# Crear un mapa de calor para visualizar la matriz de confusión\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.xlabel('Predicciones')\n",
        "plt.ylabel('Valores Verdaderos')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8ko_te3h_Eez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15.- Validación cruzada: comparar y evaluar el rendimiento de los diferentes modelos en términos de accuracy y otros métricas de evaluación."
      ],
      "metadata": {
        "id": "mQTw30W7GayL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Definir las características (X) y la variable objetivo (y)\n",
        "X = df_encoded.drop(['Drug_1', 'Drug_2', 'Drug_3', 'Drug_4'], axis=1)\n",
        "y = df_encoded[['Drug_1', 'Drug_2', 'Drug_3', 'Drug_4']]\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar las características\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Modelo Random Forest original\n",
        "rf_model_original = RandomForestClassifier(random_state=42)\n",
        "rf_model_original.fit(X_train_scaled, y_train)\n",
        "y_pred_rf_original = rf_model_original.predict(X_test_scaled)\n",
        "\n",
        "# Evaluar el rendimiento del modelo Random Forest original\n",
        "accuracy_rf_original = accuracy_score(y_test, y_pred_rf_original)\n",
        "classification_report_rf_original = classification_report(y_test, y_pred_rf_original, zero_division=1)\n",
        "\n",
        "print(\"Resultados Random Forest Original:\")\n",
        "print(f\"Accuracy del modelo de Random Forest: {accuracy_rf_original:.4f}\")\n",
        "print(\"Reporte de clasificación del modelo de Random Forest:\")\n",
        "print(classification_report_rf_original)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Modelo Random Forest con validación cruzada\n",
        "rf_model_crossval = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Realizar validación cruzada\n",
        "cv_scores = cross_val_score(rf_model_crossval, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"Resultados Random Forest con Validación Cruzada:\")\n",
        "print(\"Accuracy en validación cruzada:\")\n",
        "print(cv_scores)\n",
        "print(f\"Accuracy promedio en validación cruzada: {cv_scores.mean():.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Explorar otros modelos: Regresión Logística y K-Nearest Neighbors\n",
        "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Entrenar un modelo para cada etiqueta\n",
        "y_pred_logistic = []\n",
        "\n",
        "for label in y.columns:\n",
        "    y_train_label = y_train[label]\n",
        "    logistic_model.fit(X_train_scaled, y_train_label)\n",
        "    y_pred_label = logistic_model.predict(X_test_scaled)\n",
        "    y_pred_logistic.append(y_pred_label)\n",
        "\n",
        "# Convertir la lista de predicciones a un array\n",
        "y_pred_logistic = np.array(y_pred_logistic).T\n",
        "\n",
        "# Calcular el F1-score macro y ponderado para el modelo de Regresión Logística\n",
        "f1_macro_logistic = f1_score(y_test, y_pred_logistic, average='macro')\n",
        "f1_weighted_logistic = f1_score(y_test, y_pred_logistic, average='weighted')\n",
        "\n",
        "# Imprimir resultados por etiqueta\n",
        "for i, label in enumerate(y.columns):\n",
        "    precision = precision_score(y_test[label], y_pred_logistic[:, i])\n",
        "    recall = recall_score(y_test[label], y_pred_logistic[:, i])\n",
        "    f1 = f1_score(y_test[label], y_pred_logistic[:, i])\n",
        "\n",
        "    print(f\"Etiqueta: {label}\")\n",
        "    print(f\"Precisión: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Explorar el modelo K-Nearest Neighbors\n",
        "knn_model = KNeighborsClassifier(n_neighbors=10, weights='distance', p=2)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Calcular el accuracy para el modelo de K-Nearest Neighbors\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "classification_report_knn = classification_report(y_test, y_pred_knn, zero_division=1)\n",
        "\n",
        "print(\"Resultados K-Nearest Neighbors:\")\n",
        "print(f\"Accuracy del modelo de K-Nearest Neighbors: {accuracy_knn:.4f}\")\n",
        "print(\"Reporte de clasificación del modelo de K-Nearest Neighbors:\")\n",
        "print(classification_report_knn)\n"
      ],
      "metadata": {
        "id": "zTP4zQcnGRJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Informe rendimiento de Modelos de Clasificación\n",
        "\n",
        "### Resumen:\n",
        "\n",
        "#### Este informe detalla el proceso de evaluación y comparación de dos modelos de clasificación: Random Forest y K-Nearest Neighbors (KNN). El objetivo es comprender y analizar el rendimiento de estos modelos en la tarea de clasificar medicamentos basados en características médicas.\n",
        "\n",
        "### Modelo Random Forest Original (Sin ajustes de hiperparámetros)\n",
        "\n",
        "#### Se entrenó con el conjunto de entrenamiento escalado y se evaluó su rendimiento en el conjunto de prueba. Se calcularon métricas como: Exactitud (accuracy), precisión, recuperación y F1-score, para cada clase y se generó un reporte de clasificación\n",
        "\n",
        "### Modelo Random Forest con Validación cruzada:\n",
        "\n",
        "#### Se evaluó mediante validación cruzada para obtener una medida mas robusta del rendimiento. Se calculó el promedio de exactitud en las particiones de validación.\n",
        "\n",
        "### Modelo de Regresión Logística:\n",
        "\n",
        "### Se transformaron las etiquetas a formato binario y se ajustó el modelo. Se calcularon las probabilidades de predicción y se estableció un umbral para obtener predicciones binarias. Se calcularon F1-score macro y ponderado para este modelo\n",
        "\n",
        "### Resultados K-Nearest Neighbors\n",
        "\n",
        "#### Se entrenó con el conjunto de entrenamiento escalado y se evaluó su rendimiento en el conjunto de prueba. Se calcularon métricas de clasificación como: precisión, recuperación y F1-score para cada clase.\n",
        "\n",
        "#### EL objetivo de este análisis es evaluar la capacidad de los modelos para predecir correctamente las etiquetas de los medicamentos basados en las características médicas proporcionadas. La precisión, recuperación y F1-score, para medir el rendimiento de los modelos en términos de predicciones correctas y el equilibrio entre precisión y recuperación.\n",
        "\n",
        "### Conclusiones y Observaciones:\n",
        "\n",
        "#### 1.- El modelo Random Forest Original muestra un rendimiento excelente con una exactitud del 100%, sin embargo, se necesita precaución ya que el modelo puede estar sobreajustando los datos.\n",
        "\n",
        "#### 2.- El modelo random Forest con Validación cruzada, proporciona una medida mas realista del rendimiento y muestra una exactitud primedio del 94,37%, lo que sugiere un buen desempeño generalizado.\n",
        "\n",
        "#### 3.- La evaluación por etiqueta en ambos modelos de Random Forest, revela que el modelo es más fuerte en la predicción de \"Drug_3\", con una precisión, recuperación y F1-score del 100%.\n",
        "\n",
        "#### 4.- El modelo de Regresión Logística muestra buenos resultados, con F1-score macro y ponderado en línea con el modelo Random Forest.\n",
        "\n",
        "#### 5.- El modelo K-nearest neighbors alcanza una exactitud del 92.5%, con un rendimiento sólido en la mayoría de las métricas de clasificación.\n",
        "\n",
        "### Posibilidades de Iteración y Rectificación\n",
        "\n",
        "#### 1.- Considerar ajustar hiperparámetros en el modelo Random Forest para evitar el sobreajuste.\n",
        "\n",
        "#### 2.- Explorar otros algoritmos de clasificación tales como: Support Vector Machines o Grgadient boosting.\n",
        "\n",
        "#### 3.- Realizar una búsqueda más exhaustiva de hiperparámetros para cada modelo\n",
        "\n",
        "#### 4.- Relizar un análisis más profundo de las características para entender su importancia en la clasificación.\n",
        "\n",
        "### Elección del modelo\n",
        "\n",
        "### Dependerá de los objetivos y requisitos específicos, en caso de que la prioridad sea la precisión, el modelo Random Forest con Validación Cruzada es una opción sólida. Si se necesita un modelo interpretable, la Regresión Logística podría ser preferible. En general Random Forest y KNN, ofrecen rendimiento respetable y podrían ser considerados en diferentes contextos.\n"
      ],
      "metadata": {
        "id": "6GVzTA1gRJuP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FlgtKsslUxEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}